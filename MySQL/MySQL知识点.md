# 基础知识

## 架构

MySQL（服务端）主要分为Server层与存储引擎层

Server层：涵盖MySQL的大多数核心服务功能，一些函数处理，权限校验等，非存储引擎层做的功能都在Server层；主要包括：连接器、查询缓存、分析器、执行器等

存储引擎层：负责数据的**读写**（所有数据的变更都是在存储引擎存处理）；



**问题点：**

1. 一个SQL的执行过程是什么？连接器 -> 查询缓存 -> 分析器 -> 优化器 -> 执行器 -> 存储引擎（大概的过程，缺个图表现）
2. 短连接与长连接区别？建立的方式有是否不同？
3. MySQL能管理的连接数上限
4. 连接池是什么？
5. mysql为什么在连接释放之后才对资源进行释放？
6. mysql的wait_timeout参数是针对长连接还是短连接？



## 事务

（个人理解）数据库提供的最根本的能力就是事务（即ACID能力），只要理解了事务就是理解了数据库；

可以横向与NoSQL数据库进行对比，加深对事务的理解或事务实现过程的理解；

事务是需要保证ACID特性，其中数据库层面其实是处理了**AID**，即一致性是以应用层视角来看的；



### 原子性

**定义：**

**实现：**MySQL通过undo log实现了事务的原子性，实现了回滚；



### 一致性

**定义**：

**实现**：



### 隔离性

**定义**：

**实现**：MySQL通过MVCC + 锁的方式实现了事务的隔离性



### 持久性

**定义**：

**实现**：通过RedoLog实现持久性



## 日志

了解MySQL的日志其实就了解了事务的持久性（D）与事务的原子性（A）

结合事务ACID的定义来理解redoLog；或者我们可以想想如何实现事务的持久性？

### BinLog（归档日志）

#### 是什么？解决什么问题？

**定义**：BinLog是数据库Server层的数据，是逻辑日志，即标识了某行数据的变更前数据、变更后数据、什么操作（insert、update、delete）等信息；

同时BinLog文件是一个增量追加文件，即一个文件写完后，继续再另一个文件中写入；（与redis的AOF文件类似）



**解决问题**

主要是为了数据归档和数据恢复



### Redo Log

#### 是什么？解决什么问题？

**定义**：Redo Log 是innodb引擎特有的日志。Redo Log是物理日志，不是逻辑日志（不是记录的数据库某行某列数据的修改，BinLog记录的是逻辑日志），记录的是物理页上数据的修改（个人理解，类似记录了文件的修改）。

Redo Log 是一个先写日志，即WAL（Write-Ahead-Logging），innodb**保证事务持久性**的能力就是通过写入Redo Log 来实现的，即只要保证Redo Log写入成功，就保证事务被持久化了。（实际Redo Log的刷盘操作是由参数配置的，所以存在丢数据的可能）



**解决的问题**

MySQL数据修改后，直接将数据页更新写入磁盘（刷脏页）的成本高（磁盘IO为随机写）；

所以通过WAL的方式，来提高磁盘写的效率（减少写入次数，减少每次写入的时间）



**MySQL为什么采用WAL而不采用直接刷脏页的方式来持久化**

1. **数据量少**：刷脏页会对整个数据页进行写，而WAL是增量数据或部分数据，写入的数据量少
2. **IO效率高**：刷脏页采用的是随机写（需要先找到数据在磁盘的位置，即寻址，然后再将数据写入磁盘），而WAL是顺序写，直接在文件末尾追加，写入速度快
3. **组提交机制**：redo Log在写入磁盘时，会将一组redo log日志一起写入磁盘，减少了磁盘IO的写入次数



#### 结构是什么？如何存储和使用？（学习时与redis的AOF对比）

**redoLog是一个固定大小的文件**，一般大小为4G

<img src="img/redoLog-str.png" alt="img" style="zoom:50%;" />

环形数据的通用用法，双指针策略循环写（与redis 主从复制的replication buffer对比）

1. write pos如果追上了checkPoint 则触发redoLog的删除，即将数据删除；
2. redoLog也会定期擦除数据；

redoLog擦除数据时，都会触发刷脏页的过程，将内存中的数据刷入磁盘，不然直接擦除redoLog的数据，而数据却没有持久化就会出现数据丢失的情况。

**脏页**：当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”；

**刷脏页**：将内存中脏页的数据更新到磁盘上。（涉及到write 和 fsync 这两个系统调用）



有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为**crash-safe**。

即redolog 保证了未写入磁盘的数据在异常崩溃时，可以正常恢复。



留个问题：如果同一页数据中同一位置的数据被修改多次，redo Log是怎么记录的？是记录多条记录？还是怎么处理？

##### Redo Log 写入过程

说redo log写入前，我们先看下一个写SQL执行的过程（浅色的为存储引擎处理，深色部分为Server层处理）

<img src="img/sql-exe1.png" alt="img" style="zoom:50%;" />



一个**事务提交**（对应SQL中的commit语句）过程主要步骤如下

1. 更新内存中数据页的数据（脏页）；innodb存储引擎处理
2. 写入redoLog，但是此时redoLog为prepare状态；innodb存储引擎处理
3. 写入BinLog；Server层处理
4. 写入redoLog，此时redoLog状态为commit状态（与commit语句不同，只是redoLog的一行数据）；innodb存储引擎处理

从上述过程可以看出，MySQL采用了**两阶段提交**的方式来保证binlog 与 redoLog数据的一致性



**事务成功与持久化**

MySQL保证，客户端执行commit语句后，服务端返回成功，那数据一定被持久化（即整个redoLog已经写完，即上图中的redoLog写入commit数据完成）；

客户端执行commit语句后，服务端返回失败，那数据一定不会被持久化；

客户端执行commit语句，服务端返回异常，那MySQL只保证内部数据的一致性，需要客户端再通过查询来判断事务是否提交（数据是否被持久化）；



##### redoLog怎么对数据进行恢复（怎么保证crash-safe的）

我们来看redoLog是保证在异常崩溃情况下，怎么保证数据不会丢失的；（这也是持久性的特征）

我们来看两种情况，即在上图的两个不同时刻崩溃的场景

**场景一：在写入redoLog（prepare）后出现异常崩溃**

由于redoLog未提交，且BinLog文件未生成，所以事务未提交成功，数据回滚；

**场景二：在写入binLog之后，redoLog（commit）之前崩溃**

redoLog在恢复数据时，会将prepare状态的数据和对应的binlog数据。

如果prepare数据对应的BinLog数据未生成，则数据回滚（参考场景一）；

如果prepare数据对应的BinLog数据已生成，则将redoLog的数据commit，保证redoLog数据与binlog数据一致；

（注：此处两阶段提交的实现可以参考RocketMq中事务消息的实现，逻辑与此类似）



##### Redo Log 持久化机制

介绍RedoLog持久化机制前，先介绍Redo Log buffer

redo Log buffer是一段内存缓冲区，redo log写入时会先写入这段缓冲区中，之后由一个后台线程（每秒一次轮询）去将缓冲区中的数据写入磁盘（redo Log持久化策略后面说）；这个过程其实与redis 写AOF文件很类似



为了控制redo log的写入策略，InnoDB提供了**innodb_flush_log_at_trx_commit**参数，它有三种可能取值：

1. 设置为0的时候，表示每次事务提交时都只是把redo log留在redo log buffer中;
2. 设置为1的时候，表示每次事务提交时都将redo log直接持久化到磁盘（对应两个系统调用write() 与 fsync() ）；
3. 设置为2的时候，表示每次事务提交时都只是把redo log写到page cache（操作系统的文件缓冲区，对应系统调用就是write() 方法）



#### BinLog与RedoLog 对比

1. redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。
2. redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。
3. redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。



### Undo Log

参考事务隔离级别相关内容



### 相关问题

**RedoLog文件满了之后，如何处理？擦除数据是否有丢失数据的风险？**



**MySQL的Redo Log为什么要设计成两阶段提交？**

类似分布式事务，保证不同端数据的一致性



**MySQL为什么会既有BinLog 又有 RedoLog？**



**只保留BinLog或RedoLog 是否可以？**





## 事务隔离

### 事务隔离级别

**读未提交（read uncommitted）**：可以读取其它事务未提交的数据；

**读已提交（read committed）**：可以读取到其它事务已提交的数据，不能读取未提交的数据；

**可重复读（repeatable read）**：一个事务在执行过程中看到的数据，总是和该事务刚启动时看到的数据一致，即在同一事务中多次读取同一条记录结果是一样的，但不能读取其它事务未提交的数据；

**串行化（serialization）**：串行化的读写数据，即对同一行的数据的**读** 与 **写** 操作都会加锁，后一个事务必须等前一个事务释放锁之后才能进行读写；



不同隔离级别需要解决的问题：

**脏读（dirty read）**：读到其它事务还未提交的数据

**不可重复读（unrepeatable read）**：同一个事务对相同记录的多次查询，得到的结果却不相同，即查询到了其它事务修改后的数据

**幻读（phantom read）**：当某个事务在读取某个范围内数据的时候，此时其它事务在该范围内插入了记录，这时前一个事务在读取该范围内的数据时，会出现幻行，即多了一条记录。（Innodb通过MVCC + Next-key解决了幻读的问题）



![img](img/trx-solve-problem.png)



### 事务隔离的实现

MySQL是通过MVCC（multi version concurrent control）实现的事务的隔离；

关键点就是要理解 **多版本** 是什么？怎么用的？怎么通过多版本控制一致性读的？

#### 快照读与当前读

快照读和当前读都是去解决事务隔离性的问题

**快照读（read view）**：事务在开启时，与结束前这个过程中读取的数据是一致的，也就是一致性读（consist read）

**当前读（current read）**：读取的是最新事务修改后的数据



**触发快照读的条件**：在RR级别下，每次select 查询都是快照读；事务开启时会有快照数据（不是真的存了所有数据的内存快照），每次查询都是读这个快照

**触发当前读的条件**

1. 在RC隔离级别下，每次select 查询都是读取最新的快照（不是事务开始时的快照）
2. 在RR隔离级别下，update、delete、select...for update、select ... in share mode 这些语句都会获取最新快照数据；（如果不获取最新的数据，其它事务提交的数据就会被覆盖，造成更新丢失）



#### 事务Id

MySQL中会在每个事务创建的时候，为它分配一个事务Id，这个事务Id是一个**单调递增**的数字。

所以通过事务Id就可以判断事务创建的先后。



#### Innodb的隐藏列

innodb在每行数据中都设置了三列隐藏列，分别是row_id（行Id）、trx_id（事务Id）、roll_ptr（回滚指针）

**row_id**：隐藏的行ID，用来生成默认聚集索引。如果我们创建数据表的时候没有指定聚集索引，这时InnoDB就会用这个隐藏ID来创建聚集索引。

**trx_id**：事务Id，标识修改当前行的事务Id

**roll_ptr**：回滚指针，是一个指针，指向当前数据需要回滚的上一个数据行；



![img](https://static001.geekbang.org/resource/image/47/81/4799c77b8cdfda50e49a391fea727281.png)



从上图可以看出，MySQL中一条行记录可能同时对应多个版本，而不同版本之间通过roll_ptr指针连接，我们通过roll_ptr 就可以找到历史版本对应的数据，这个也就是所谓的**多版本控制**。

每个版本的数据，其实就是某个事务对该行的修改结果，所以每个版本数据都有对应的trx_id；



#### Read View的工作原理（MVCC）

**快照读的本质（个人理解）** ：在事务开启后，能找到在**当前事务开启之前提交的数据**（或当前事务提交的数据），而看不到在当前事务开启之后提交的数据

**快照读的实现**

1. 事务开启时，获取当前所有**活跃中的事务Id**（开启了事务，但却没有提交）
2. 根据活跃事务Id维护一个read view的数据结构，包括trx_ids（**活跃中的事务Id列表**）、low_limit_id（**活跃的事务中最大的事务ID**）、up_limit_id（**活跃的事务中最小的事务ID**）、creator_trx_id（**当前事务ID**）
3. 通过比较当前事务Id 和 行版本中的事务Id，来获取最近已提交的数据（当前事务开启之前提交的数据或当前事务提交的数据）
4. 如果当前数据行的事务Id不可见，则通过回滚指针找到上一个版本的数据，再接着根据事务Id判断可见性

<img src="https://static001.geekbang.org/resource/image/88/5e/882114aaf55861832b4270d44507695e.png" alt="img" style="zoom:50%;" />



所以问题就转变为：**如何根据活跃事务Id和当前事务Id，来判断该版本的数据是否对当前事务可见（即当前事务能不能看到这个版本的数据）**

从上图我们可以得出以下几个场景：

1. 读取的数据行的事务Id  < up_limit_id（活跃的事务中最小的事务ID），那该事务是已提交的事务，那么**数据一定可见**；
2. 读取的数据行的事务Id  > low_limit_id（活跃的事务中最大的事务ID），该事务是在当前事务启动之后开启，那么**数据一定不可见**；
3. up_limit_id < 读取的数据行的事务Id < low_limit_id，这时有三种情况
   1. 读取的数据行的事务Id 是 trx_ids（活跃事务Id）中的事务，事务还未提交，则**数据不可见**；
   2. 读取的数据行的事务Id 是 creator_trx_id （当前事务Id），则**数据可见**；
   3. 读取的数据行的事务Id 不是 trx_ids（活跃事务Id）中的事务，说明事务已经提交了，则**数据可见**；

如果数据不可见，则通过回滚指针找到上一个版本的数据再进行判断



**注意点**：

1. **减少事务时间**：由于Read view保存了多个版本的数据，如果我们开启大事务就会导致回滚段中有大量的数据，会对MySQL的性能造成影响；



#### 解决幻读问题

**场景**：在RR隔离级别下，正常都是快照读，只有触发当前读才可能导致幻读问题；

**原因**：幻读的根本原因是，我们只对数据行进行了加锁（行锁），但是没有对insert 进行锁定，所以导致查询的数据变多了；

**解决方案**：innodb通过间隙锁的方式，将行行之间进行锁定，阻止了 insert；（同时间隙锁也只有在RR级别下才会有，更多间隙锁的知识参考锁章节）



## 索引

### MySQL存储结构

MySQL采用B+树来进行数据的存储；

B+树上每个节点都会持久化到磁盘中，也就是MySQL中的**页**（Page）；

MySQL的页是数据存储的最小单位，每页大小为16KB；



**B+树结构特点**



**为什么不使用二叉树来存储？**

二叉树存储每层节点数较少（2^n，n为层数 ），会导致树的层数比较高；

由于层数较多，不同层会分开存储，查询时会导致多次磁盘IO，影响查询速度；



**为什么不使用B数来存储？**

因为B树不仅叶子节点会存储数据记录（即完整的行记录），中间节点也会存储数据记录；这样中间的索引节点存储的数据较多，每页存储的索引行较少，就导致B树的层数会比B+树的层数高；层数越少，磁盘IO次数越少，查询效率越高；

即B+树从结构上看会比B树更加矮胖（每页存储更多的数据，有更少的层数）；



### 索引存储结构

MySQL的索引页采用B+树存储；

非主键索引（聚簇索引）上只存储索引的值 + 主键索引的对应的值（值 + 页指针）；



### 索引类型

#### 聚簇索引

也是主键索引，innodb中会将数据按照主键索引进行保存，即建立一个以主键为索引的B+树，叶子节点存储**主键的值和整个行记录；**



#### 唯一索引

索引的值是唯一的，不会重复；

mysql在使用唯一索引进行查找时，如果找到对应的记录就不会再继续进行查找；



#### 二级索引

非唯一索引，即索引中字段的值可以重复；

MySQL在使用二级索引进行查找时，再找到符合条件的值后，还会继续向后搜索，直到查到一条不匹配的记录；



### 索引使用

#### 索引查询与回表

**主键索引的查询**：由于mysql是采用聚簇索引的方式来存储数据，所以通过主键查询时，会直接查到对应的行记录；

**非主键索引的查询**：通过非主键索引查询只会得到对应索引的值和对应主键的值（索引 + 主键）；

**回表**：如果非主键索引查询，需要的数据需要额外的字段就会触发一个回表，即通过索引中记录的主键找到对应的行记录；



#### 覆盖索引

如果一次查询所需要的字段，当前的索引可以全部覆盖，那么查询到找到索引就可以结束，直接将索引的记录返回即可，不再需要回表；

较优的索引，减少了一次回表的查询操作；



#### 前缀索引

**定义**：如果某个字段过长，同时只有某几位区分度比较高，我们就可以对该字段前几位进行截断建立索引；

索引字段过大，会导致索引效率低，因为mysql的页大小是固定的，所以索引字段越大，每页存储的数据就越少，那么查询需要扫描的页就可能会增多；



#### 最左前缀原则

索引查询时，都是按照从左到右依次匹配的，只有前一个索引生效的情况下，才会使用到下一个索引；

比如联合索引（a,b），查询时使用 where a = 1 and b = 2 则查询是可以使用索引的；如果条件是where b = 1 由于不符合最左前缀规则，则是无法使用索引的；



索引使用时，这些情况是会导致下个索引无法生效：

1. 前一个索引存在范围查询，如：>、<、>=、<= 
2. 前一个索引存在模糊查询，如：like查询



#### 索引下推

查询时，由于某些原因导致只有部分索引生效，剩余的字段无法直接使用索引，但是由于索引中会存储索引列的值，所以MySQL会使用索引中的值，不再回表查询其它字段的数据，直接在内存中进行过滤。

比如：存在联合索引（a, b），查询条件为 where a like '数据%' and b = 2，那么这时只有a会用到索引，但是MySQL会取出索引的值，在内存中过滤，而不用回表再查b的值；



#### order by



#### group by



**相关问题**

为什么MySQL采用B+树，不采用B树？（见上）



## 锁

### 表锁

**DML锁**：

**意向锁**

意向共享锁（IS）

意向互斥锁（IX）



意向锁之间不会互斥；



### 行锁

**共享锁**（S锁）：

**互斥锁**（X锁）：





### 间隙锁

对行记录之间的间隙进行锁定，主要是防止插入操作；

RR级别下才会存在间隙锁；



### 加锁规则

MySQL的加锁是通过在索引上加锁实现的；

特殊情况：覆盖索引的场景下不会对主键索引进行加锁，只对索引进行加锁；



**（引用网上的，非原创）我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。**

1. 原则1：加锁的基本单位是next-key lock。希望你还记得，next-key lock是前开后闭区间。
2. 原则2：查找过程中访问到的对象才会加锁。
3. 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。
4. 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。
5. 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

范围查询会加next-key lock 且不会被优化；



### 死锁检测





## 主从

### 主从复制原理



### 主从延迟

#### 主从延迟的影响



#### 出现主从延迟的原因



#### 主从延迟的解决方案



# 实践

### 分库分表

#### 为什么要分库分表？

1. **单机的读写性能的上限**：单表或者单库能承担的TPS有限；
2. **数据备份和DDL的瓶颈**：整库的备份或大表的DDL会很耗时，且风险较大；



#### 什么样的场景需要分库分表？

个人认为大部分场景都不需要进行分库分表；比如只是数据量大，那可以通过数据归档的方式将冷数据进行归档；

需要分库分表的场景（个人理解）

1. 存在大量的热点数据，比如TPS特别高，一天百万或千万的数据，且同一时间数据的写入量较大；
2. 存在支持大量的数据查询（次要原因），比如单日数据量不高（单日十万的数据），但需要支持全量数据的查询，且查询时效性要求高（否则可以通过hive存储即可）；



#### 如何进行分库分表设计？

分库分表分为**垂直拆分**和**水平拆分**

垂直拆分（针对结构的拆分）：按照业务功能或者服务进行拆分，即将一张大表拆分为多个小表，分开维护；（垂直拆分表结构发生了变更）

水平拆分（针对数据的拆分）：将一张表中的数据拆分到多张相同的表中进行存储；（水平拆分表结构不变，只是不同的表存储不同的数据）



**分表键选择**

1. 确定业务主体（能体现业务属性或业务操作），比如是面向用户或者面向商户的操作，即可将用户或者商户当成分表键；
2. 确定不了业务主体的，就按照某个业务字段，保证数据的均匀分布，避免出现热点数据，即同一时间数据全部写入一张表中；

个人理解分表键的选择主要从数据写入角度考虑（尽量保证数据分布均匀，避免热点数据），其次再考虑数据的查询（一个查询尽量在一张表中，避免跨库跨表、联表的查询）；



**唯一ID**

在单表中可以通过自增主键实现唯一Id；

但分库分表后，唯一定位一条数据就无法直接通过表的自增Id来实现了（多张表中会出现相关的Id）；

唯一Id也可以有业务含义：比如订单号生成可以为 ： **时间戳 + 用户Id（部分位） + 随机数**

**实现方案**

参考：https://segmentfault.com/a/1190000021175381

**1. 利用数据库自增Id，比如有一张表专门负责自增Id的获取；**

优点：简单

缺点：单机风险、单机性能瓶颈；



利用集群数据库 + 步长的方式（Flickr方案）



**2. 中间件实现发号器，比如leaf 通过snowflake 算法来生成**

优点：



**分片数选择**（确定需要分的库表数量）

1. 单表行数建议小于1000万行；（分表的数量）
2. 单库大小小于300G；（分库的数量）

**分片策略选择**

Hash：用分表键的值Hash取模进行路由；数据分布较为均匀

范围切分：比如按照时间范围划分（一月份数据是一张表、二月是一张表），或按照id区间进行区分；容易造成热点数据



#### 分库分表面临哪些问题？

**跨库事务问题**

1. 尽量避免分布式事务，即同一个事务下的写操作保证在同一个库中；
2. 无法避免时，只能采用分布式事务；需要中间件支持，一般方案是两阶段提交、三阶段提交等；



**数据迁移**

hash的方式建议一次性分库分表够用，避免数据迁移；采用一致性hash的方式；

库表的数量为2的整数幂



**所有库表的DDL操作怎么执行**





**非分表键维度的查询怎么处理**

**注意：分库分表后的查询一定要带上分库键，否则会触发所有库表的查询，有导致系统崩溃的风险**

1. 使用辅助键进行查询

   比如将用户Id为分表建，查询某个用户最近一天的订单，则我们在生成订单的时候保证orderId的有序

2. 建立索引表

   比如分表键为a，查询条件只有b，则建立一个(b, a)关系的索引表（索引表也可以分表存，分表键为b），先通过索引表查询出分表键a，然后在用分表键a查询

3. 异步存储数据（造成数据冗余，以空间换时间）

   比如通过监听binlog 再重建一个按照时间维度分片的全量分库分表数据；（多个维度会建立多个全量副本，成本较高）

   使用分布式数据库，比如TiDB，只建立一套数据即可，内部支持多个维度的查询；（时效性要求不高的场景）

   



## 相关链接

### 推荐书籍

<< Design Data-intensive Application >>

<<高性能MySQL>>

<<MySQL内核 Innodb存储引擎>>
